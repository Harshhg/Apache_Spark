{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing findspark and initializing \n",
    "import findspark\n",
    "findspark.init('/home/ec2-user/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pyspark\n",
    "import pyspark\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling SparkContext \n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pair RDD\n",
    "my_tuple = [('Harsh',20), ('Ankit',21), ('Harshit',22)]\n",
    "regular_rdd = sc.parallelize(my_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Transformations on Pair RDDs\n",
    "# We have to pass functions that operate on key value pairs rather than on individual elements.\n",
    "# Examples of pair RDD transformation -\n",
    "    # reduceByKey(func)  - Combine values with the same key.\n",
    "    # sortByKey()  -  Return an RDD sorted by the key.\n",
    "    # groupByKey()  -  Group values with the same key.\n",
    "    # join()  -  Join two pair of RDDs based on their key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harsh', 35), ('Ankit', 21), ('Harshit', 22)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying reduceByKey() Transformation\n",
    "# Creating Key value pair RDD with duplicate keys\n",
    "my_list = [(\"Harsh\",20), (\"Ankit\",21), (\"Harshit\",22), (\"Harsh\",15)]\n",
    "my_rdd = sc.parallelize(my_list)\n",
    "\n",
    "# passing function that add values of keys that are similar.\n",
    "pairRDD_reducebykey = my_rdd.reduceByKey(lambda x,y : x + y) \n",
    "pairRDD_reducebykey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ankit', 21), ('Harsh', 20), ('Harshit', 22)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying sortByKey() Transformation\n",
    "    # Sorting the \"key\"..\n",
    "pairRDD_sortbykey = regular_rdd.sortByKey(ascending=True) # Sorts in Ascending order.\n",
    "pairRDD_sortbykey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(22, 'Harshit'), (21, 'Ankit'), (20, 'Harsh')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Sorting the \"value\"\n",
    "x = regular_rdd.map(lambda x: (x[1], x[0])) # Reverse the list and creates new RDD.\n",
    "y = x.sortByKey(ascending=False)  # Sorts in Descending order.\n",
    "y.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harsh [20, 15]\n",
      "Ankit [21]\n",
      "Harshit [22]\n"
     ]
    }
   ],
   "source": [
    "# Applying groupByKey() Transformation\n",
    "pairRDD_groupbykey = my_rdd.groupByKey().collect()\n",
    "for key,value in pairRDD_groupbykey:\n",
    "    print(key,list(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Harsh', (20, 28)), ('Ankit', (21, 26))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying join() Transformation\n",
    "rdd1 = sc.parallelize([(\"Harsh\",20), (\"Ankit\",21), (\"Harshit\",22)]) # Creating 1st RDD.\n",
    "rdd2 = sc.parallelize([(\"Dhruv\",19), (\"Ankit\",26), (\"Harsh\",28)]) # Creating 2nd RDD.\n",
    "\n",
    "# Joining RDDs based on their key.\n",
    "# Only joins the elements that are same in both RDDs.\n",
    "rdd1.join(rdd2).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
